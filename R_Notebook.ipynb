{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET ANALYSE DE DONNEES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "library(ggforce)\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(FactoMineR)\n",
    "library(factoextra)\n",
    "library(gridExtra)\n",
    "library(cluster)\n",
    "library(dendextend)\n",
    "library(dplyr)\n",
    "library(mclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loading <- read.csv(\"data/velibLoading.csv\", sep = \" \")\n",
    "head(loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Coord <- read.csv(\"data/velibCoord.csv\", sep = \" \")\n",
    "head(Coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche maintenant à voir si les deux tableaux contiennent des données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print('--Loading--')\n",
    "any(is.null(loading)) \n",
    "#Nous n'avons pas de données manquantes dans les colonnes de loading \n",
    "print('--Coord--')\n",
    "any(is.null(Coord))\n",
    "#pareil pour coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche également à voir si certaines données sont dupliquées dans les deux df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print('--Loading--')\n",
    "any(duplicated(loading)) \n",
    "#Nous n'avons pas de données dupliquées dans les colonnes de loading \n",
    "print('--Coord--')\n",
    "any(duplicated(Coord))\n",
    "#pareil pour coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Changement des options graphiques\n",
    "options(repr.plot.width = 10, repr.plot.height = 10, repr.plot.res = 100)\n",
    "#On affiche le chargement de la 1ère station\n",
    "\n",
    "#On créé une séquence de temps\n",
    "p <- ncol(loading)\n",
    "Time <- seq(1, p)\n",
    "\n",
    "#On garde seulement la 1ère station\n",
    "loading_transposed <- t(loading)\n",
    "first_column <- loading_transposed[, 1]\n",
    "\n",
    "plot(Time, first_column, type = \"l\", lwd = 2, col = \"blue\", xlab = \"Time\", ylab = \"Loading\", main =Coord$names[1])\n",
    "abline(v = seq(1, p, length.out = 8), col = \"black\", lty = \"dotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va désormais parcourir les 16 premières stations pour afficher leur chargement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(4, 4), mar = c(4, 4, 2, 1)+ 0.1, oma = c(0, 0, 4, 0)+ 0.1, mgp = c(3.5, 1.5, 0))\n",
    "\n",
    "p <- ncol(loading)\n",
    "Time <- 1:p\n",
    " \n",
    "for (i in 0:3) {\n",
    "  for (j in 0:3) {\n",
    "    id_station <- 4 * i + j + 1\n",
    "    plot(Time, loading_transposed[, id_station], type = \"l\", col = \"blue\", lwd = 2, xlab = \"Time\", ylab = \"Loading\",\n",
    "         main = Coord$names[id_station])\n",
    "    abline(v = seq(1, p, length.out = 8), col = \"black\", lty = \"dotted\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot des chargements pour chaque heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bp <- boxplot(as.matrix(loading), \n",
    "              col = \"white\", border = \"black\", median.col = \"red\",\n",
    "              staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "              names = rep(\"\", ncol(loading)))\n",
    "\n",
    "abline(v = seq(1, ncol(loading), length.out = 8), col = \"purple\",lwd=4)\n",
    "\n",
    "\n",
    "title <- \"Boxplots\"\n",
    "ticks <- seq(0, 168, by = 5)\n",
    "labels <- seq(0, 168, by = 5)\n",
    "title(main = title, cex.main = 1.25)\n",
    "axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "mtext(\"Loading\", side = 2, line = 2, cex = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les jours de la semaine ont des comportements similaires entre eux. On voit aussi que les deux jours de week-end se ressemblent. <br>\n",
    "<br>\n",
    "## Moyenne de chargement par heure pour chaque jour de la semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "MoyHeures <- colSums(loading) / 1189\n",
    "\n",
    "\n",
    "jours <- c(\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\")\n",
    "\n",
    "MoyHeuresPJours <- matrix(MoyHeures, nrow = 24)\n",
    "MoyHeuresPJours <- t(aperm(MoyHeuresPJours, c(2, 1)))\n",
    "\n",
    "plot(1:24, MoyHeuresPJours[,1], type = \"l\", xlab = \"Heures\", ylab = \"Loading\", \n",
    "     col = rainbow(7)[1], ylim = range(MoyHeuresPJours), \n",
    "     main = \"Moyenne de chargement par heure pour chaque jour de la semaine\")\n",
    "\n",
    "for (i in 2:7) {\n",
    "  lines(1:24, MoyHeuresPJours[,i], type = \"l\", col = rainbow(7)[i])\n",
    "}\n",
    "legend(\"topright\", legend = jours, col = rainbow(7), lwd = 2, cex =0.8, bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit des résultats similaires pour samedi et dimanche, qui ont une tendance différente des autres jours de la semaine, ce qui confirme ce qui est vu sur le boxplot.\n",
    "\n",
    "## Représentation des moyennes de chargement pour chaque heure (6h,12h,23h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On garde les coordonnées géographiques de Paris pour zoomer direct sur la ville\n",
    "paris_lon <- 2.3522\n",
    "paris_lat <- 48.8566\n",
    "\n",
    "#On garde les positions des stations\n",
    "Position <- Coord[, c(1, 2)]\n",
    "\n",
    "#On garde les heures à afficher\n",
    "a6 <- seq(6, 168, 24)\n",
    "a12 <- seq(12, 168, 24)\n",
    "a23 <- seq(23, 168, 24)\n",
    "\n",
    "#On calcule les moyennes de chargement pour chaque heure\n",
    "\n",
    "\n",
    "#----------------6h---------------------------------\n",
    "\n",
    "\n",
    "\n",
    "data6h <- rowMeans(loading[, a6])\n",
    "data6h_df <- Coord \n",
    "data6h_df$loading_six_heures=data6h\n",
    "fig6 <-plot_ly(data = data6h_df, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~loading_six_heures, colors = c(\"blue\", \"gold\"),\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data6h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\"))\n",
    "fig6\n",
    "\n",
    "\n",
    "#----------------12h---------------------------------\n",
    "\n",
    "data12h <- rowMeans(loading[, a12])\n",
    "data12h_df <- Coord\n",
    "data12h_df$loading_douze_heures=data12h\n",
    "\n",
    "fig12 <-plot_ly(data = data12h_df, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~loading_douze_heures, colors = c(\"blue\", \"gold\"),\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data12h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\"))\n",
    "fig12\n",
    "\n",
    "#----------------23h---------------------------------\n",
    "\n",
    "\n",
    "data23h <- rowMeans(loading[, a23])\n",
    "data23h_df <- Coord\n",
    "data23h_df$loading_vingt_trois_heures=data23h\n",
    "fig23 <- plot_ly(data = data23h_df, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~loading_vingt_trois_heures, colors = c(\"blue\", \"gold\"),\n",
    "                    marker = list(size = 7), text = paste(\"Loading:\", round(data23h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\"))\n",
    "fig23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des stations en fonction de leur relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On calcule la moyenne des données de chargement pour chaque ligne\n",
    "\n",
    "data24h <- rowMeans(loading)\n",
    "\n",
    "\n",
    "figbonus <- plot_ly(data = Coord, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~as.factor(bonus), colors = c(\"cornflowerblue\", \"gold\"),\n",
    "                    marker = list(size = 7), text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\"))\n",
    "\n",
    "figbonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reconnaît ici les collines parisiennes (représentées en jaune sur la carte).\n",
    "\n",
    "## Histogramme des données de chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10, repr.plot.res = 100)\n",
    "hist(unlist(loading), breaks = 64, main = \"Histogramme des données de chargement\", \n",
    "     xlab = \"Valeurs de chargement\", ylab = \"Fréquence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a beaucoup de stations très peu chargées (à une heure de donnée), difficile à interpréter.\n",
    "\n",
    "Rq: On a 1189 stations pour 168h de prélèvement de chargement donc cohérent d'avoir un nombre de 25000 en max.\n",
    "\n",
    "## Matrice de corrélation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "correlation <- cor(loading)\n",
    "\n",
    "for (k in 0:6)\n",
    "  {correlation_subset <- correlation[(1+24*k):(24*(k+1)), (1+24*k):(24*(k+1))]\n",
    "  corrplot(correlation_subset, method = \"ellipse\", type = \"upper\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les corrélations des heures pour chaque jour de la semaine et du week-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns <- c(\"Lun.12\", \"Lun.13\", \"Mar.12\", \"Mar.13\", \"Ven.12\", \"Ven.13\", \"Lun.18\", \"Ven.18\")\n",
    "\n",
    "pairs(loading[selected_columns], \n",
    "      pch = 20,               \n",
    "      col = \"skyblue\",           \n",
    "      cex = 0.3,              \n",
    "      gap = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique confirme les corrélations que l'on a pu voir sur le graphe au dessus. Par exemple Lundi-12h et Lundi 13h sont très corrélés (on observe une droite). Pour mardi et vendredi il y a aussi une corrélation entre 12 et 13h.\n",
    "\n",
    "## Comportements stations sur colline ou non\n",
    "\n",
    "### Sur colline : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#---------------Boxplot----------------\n",
    "\n",
    "loading_hill = loading[Coord$bonus==1,]\n",
    "  \n",
    "bp <- boxplot(as.matrix(loading_hill), \n",
    "              col = \"white\", border = \"black\", median.col = \"red\",\n",
    "              staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "              names = rep(\"\", ncol(loading_hill)))\n",
    "\n",
    "abline(v = seq(1, ncol(loading_hill), length.out = 8), col = \"purple\",lwd=4)\n",
    "\n",
    "\n",
    "title <- \"Boxplots sur colline \"\n",
    "ticks <- seq(0, 168, by = 5)\n",
    "labels <- seq(0, 168, by = 5)\n",
    "title(main = title, cex.main = 1.25)\n",
    "axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "\n",
    "#Comportements moyen\n",
    "MoyHeures <- colSums(loading_hill) / nrow(loading_hill)\n",
    "\n",
    "\n",
    "jours <- c(\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\")\n",
    "\n",
    "MoyHeuresPJours <- matrix(MoyHeures, nrow = 24)\n",
    "MoyHeuresPJours <- t(aperm(MoyHeuresPJours, c(2, 1)))\n",
    "\n",
    "plot(1:24, MoyHeuresPJours[,1], type = \"l\", xlab = \"Heures\", ylab = \"Loading\", \n",
    "     col = rainbow(7)[1], ylim = range(MoyHeuresPJours), \n",
    "     main = \"Moyenne de chargement sur colline par heure pour chaque jour de la semaine\")\n",
    "\n",
    "for (i in 2:7) {\n",
    "  lines(1:24, MoyHeuresPJours[,i], type = \"l\", col = rainbow(7)[i])\n",
    "}\n",
    "legend(\"topright\", legend = jours, col = rainbow(7), lwd = 2, cex =0.8, bty = \"n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les stations en hauteur, les week-ends il n'y a pas beaucoup de vélos chargés. En semaine, il y a un fort écart entre le matin et l'après-midi.\n",
    "\n",
    "### Sur stations sans relief : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#---------------Boxplot----------------\n",
    "\n",
    "loading_no_hill = loading[Coord$bonus==0,]\n",
    "  \n",
    "bp <- boxplot(as.matrix(loading_no_hill), \n",
    "              col = \"white\", border = \"black\", median.col = \"red\",\n",
    "              staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "              names = rep(\"\", ncol(loading_no_hill)))\n",
    "\n",
    "abline(v = seq(1, ncol(loading_no_hill), length.out = 8), col = \"purple\",lwd=4)\n",
    "\n",
    "\n",
    "title <- \"Boxplots pas sur colline\"\n",
    "ticks <- seq(0, 168, by = 5)\n",
    "labels <- seq(0, 168, by = 5)\n",
    "title(main = title, cex.main = 1.25)\n",
    "axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "\n",
    "#Comportements moyen\n",
    "MoyHeures <- colSums(loading_no_hill) / nrow(loading_no_hill)\n",
    "\n",
    "\n",
    "jours <- c(\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\")\n",
    "\n",
    "MoyHeuresPJours <- matrix(MoyHeures, nrow = 24)\n",
    "MoyHeuresPJours <- t(aperm(MoyHeuresPJours, c(2, 1)))\n",
    "\n",
    "plot(1:24, MoyHeuresPJours[,1], type = \"l\", xlab = \"Heures\", ylab = \"Loading\", \n",
    "     col = rainbow(7)[1], ylim = range(MoyHeuresPJours), \n",
    "     main = \"Moyenne de chargement pas sur colline par heure pour chaque jour de la semaine\")\n",
    "\n",
    "for (i in 2:7) {\n",
    "  lines(1:24, MoyHeuresPJours[,i], type = \"l\", col = rainbow(7)[i])\n",
    "}\n",
    "legend(\"topright\", legend = jours, col = rainbow(7), lwd = 2, cex =0.8, bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le comportement pour les stations plates se rapproche plus du comportement moyen, ce qui est normal car la majorité des stations ne sont pas sur des collines. \n",
    "De plus on remarque une différence moins flagrante entre la semaine et le weekend pour les stations plates.\n",
    "\n",
    "\n",
    "# PCA\n",
    "\n",
    "On a un jeu de données pour loading a 168 variables donc 168 dimensions. On veut essayer de voir si on peut se ramener à des données de plus faibles dimensions. Pour cela on va faire une Analyse en Composantes Principales.\n",
    "\n",
    "## Implémentation de la PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On normalise les données\n",
    "\n",
    "loading_scaled <- scale(loading)\n",
    "\n",
    "#Analyse en composantes principales (ACP)\n",
    "pca <- prcomp(loading_scaled)\n",
    "\n",
    "#Pour l'affichage on garde les 25 premières dimensions\n",
    "\n",
    "nb_components=25\n",
    "\n",
    "#Variance expliquée par composante principale\n",
    "barplot(pca$sdev^2 / sum(pca$sdev^2), \n",
    "        main = \"Variance expliquée par composante principale\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée\",\n",
    "        ylim = c(0, 1),\n",
    "        xlim = c(1,25))\n",
    "\n",
    "#Variance expliquée cumulée par composante principale\n",
    "barplot(cumsum(pca$sdev^2 / sum(pca$sdev^2)), \n",
    "        main = \"Variance expliquée cumulée par composante principale\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée cumulée\",\n",
    "        ylim = c(0, 1),\n",
    "        xlim = c(1,25))\n",
    "\n",
    "#On trace la limite de 70% de variance expliquée\n",
    "abline(h = 0.7, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour expliquer au moins 70% de variance, il faut garder 4 composantes principales.\n",
    "\n",
    "### Boxplots des projections des données sur les composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "C <- as.data.frame(pca$x[, 1:nb_components])\n",
    "\n",
    "boxplot(C, main = \"Boxplot des projections des données sur les composantes principales\",\n",
    "        xlab = \"Composante principale\", ylab = \"Valeur\", col = \"skyblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "Ce graphique montre une grande variance pour les 3/4 premières composantes principales, ce qui confirme le choix de garder 4 composantes.\n",
    "On voit par exemple que les individus ont en moyenne -1 pour la coordonnée sur la 1ère composante principale.\n",
    "\n",
    "\n",
    "## Projection des variables sur le plan d'ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Selon la 1ère et la 2ème composantes principales\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "grid.arrange(\n",
    "    fviz_eig(pca), \n",
    "    fviz_pca_var(pca,axes=c(1,2)),\n",
    "    ncol=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que pour les dimensions 1 et 2, toutes les flèches sont proches du cercle : les variables sont donc relativement bien expliquées par les composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Selon la 1ère et la 3ème composantes principales\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "grid.arrange(\n",
    "    fviz_eig(pca), \n",
    "    fviz_pca_var(pca,axes=c(1,3),label='none'),\n",
    "    ncol=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que pour les dimensions 1 et 3 les flèches sont plus courtes : les variables sont moins bien expliquées (ce qui est normal car la dimension 3 explique moins de variance que la dimension 2).\n",
    "\n",
    "## Qualité et contribution des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On affiche la qualité de représentation des variables : comment les axes permettent d'expliquer les variables\n",
    "q1=fviz_pca_var(pca, col.var=\"cos2\",repel=TRUE,gradient.cols=c(\"#00afbb\",\"red\",\"yellow\"),label=\"none\")\n",
    "#On affiche la contribution des variables aux axes\n",
    "c1=fviz_pca_var(pca,col.var=\"contrib\",repel=TRUE,gradient.cols=c(\"#00afbb\",\"red\",\"yellow\"),label=\"none\")\n",
    "grid.arrange(q1,c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des dimensions de l'ACP\n",
    "\n",
    "Dans cette partie, nous rappelons que les composantes principales sont des combinaisons linéaires des variables initiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(4, 2), mar = c(4, 4, 2, 1))\n",
    "\n",
    "#On utilise les 168h en x\n",
    "u <- seq(0, 168, length.out = 168)\n",
    "for (i in 1:4) {\n",
    "  plot(u, pca$rotation[, i], type = \"l\", ylim = c(-0.2, 0.2), xlab = \"Longueur d'onde\", ylab = \"\", main = paste(\"Composante\", i))\n",
    "  abline(h = mean(pca$rotation[,i]), col = \"red\",lty=2) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 4 plots représentent les coefficients pour les 168 heures, et pour les 4 premières dimensions de l'ACP.\n",
    "\n",
    "Le premier plot (sur la dimension 1) on voit que tous les coeffs sont à peu près égaux, ce qui montre que la 1ère composantes est proportionnelle à la moyenne des chargements sur toutes les stations au cours des heures.\n",
    "\n",
    "Le deuxième plot (sur la dimension 2) montre le contraste entre le jour et la nuit: en pleine journée les coeffs sont positifs alors que la nuit ils sont négatifs.\n",
    "\n",
    "Les plots 3 et 4 sont plus difficiles à interpréter, même si on remarque plutôt sur le troisième plot (dimension 3) le contraste entre les jours en pleine semaine et le week-end.\n",
    "\n",
    "\n",
    "Ce résultat se retrouve sur le cercle des corrélations : sur la composante 1, les variables ont à peu près la même coordonnées (même position sur l'axe x), tandis que sur la composante 2, il y a 2 groupes qui semblent se dégager. En haut on distingue les heures correspondant à la journée, et en bas à la nuit (les heures entre ces deux périodes : début de matinée ou fin de soirée se retrouvent avec une coordonnée proche de 0 selon l'axe y).\n",
    "\n",
    "## Projection des individus sur le plan ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_pca_ind(pca,geom=c(\"point\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualité et contribution des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On affiche la qualité de représentation et la contribution des individus\n",
    "q2=fviz_pca_ind(pca, col.ind=\"cos2\",geom=c(\"point\"),gradient.cols=c(\"#00afbb\",\"red\",\"yellow\"))\n",
    "c2=fviz_pca_ind(pca, col.ind=\"contrib\",geom=c(\"point\"),gradient.cols=c(\"#00afbb\",\"red\",\"yellow\"))\n",
    "grid.arrange(q2,c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les individus proches du centre (origine) sont mal expliqués par les composantes principales. \n",
    "Pour la contribution on voit la même chose pour les individus du centre qui contribuent moins aux composantes principales.\n",
    "\n",
    "\n",
    "# Clustering\n",
    "\n",
    "Nous allons maintenant essayer de regrouper les stations en différentes classes. Pour cela utiliser des méthodes de Clustering.\n",
    "Commenons d'abord par du clustering Kmeans.\n",
    "\n",
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "velib_PCA_reduced= C[,1:4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du nombre de clusters \n",
    "\n",
    "### Avec l'inertie : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "K=10\n",
    "Iintra=NULL\n",
    "for (k in 2:K)\n",
    "{\n",
    "  #On calcule l'inertie pour différentes valeurs de k\n",
    "  kmeans_model <- kmeans(velib_PCA_reduced, centers = k)\n",
    "  Iintra=c(Iintra,kmeans_model$tot.withinss)\n",
    "  \n",
    "}\n",
    "inertie_df=data.frame(K=2:10,Iintra=Iintra)\n",
    "ggplot(inertie_df,aes(x=K,y=Iintra))+geom_line()+geom_point()+ \n",
    "  labs(x = \"Nombre de clusters (k)\", y = \"Inertie\") +\n",
    "  ggtitle(\"Dispersion de l'inertie en fonction de k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un bon clustering minimise l'inertie intra-classes et maximise l'inter-classes. \n",
    "Pour trouver le nombre optimal de clusters, on fait la méthode du coude : on garde 4 clusters.\n",
    "\n",
    "### Méthode silhouette et WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "g1=fviz_nbclust(velib_PCA_reduced, stats::kmeans, method = \"silhouette\")\n",
    "g2=fviz_nbclust(velib_PCA_reduced, stats::kmeans, method = \"wss\")\n",
    "grid.arrange(g1,g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour silhouette on doit prendre le max -> On choisit donc de garder 3 clusters selon cette méthode\n",
    "\n",
    "\n",
    "### Graphes Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 6)\n",
    "\n",
    "#On teste pour plusieurs k différents\n",
    "\n",
    "#k=2\n",
    "kmeans_model <- kmeans(velib_PCA_reduced, centers=2, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_PCA_reduced))\n",
    "p1=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=2\")\n",
    "\n",
    "#k=3\n",
    "kmeans_model <- kmeans(velib_PCA_reduced, centers=3, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_PCA_reduced))\n",
    "p2=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=3\")\n",
    "\n",
    "#k=4\n",
    "kmeans_model <- kmeans(velib_PCA_reduced, centers=4, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_PCA_reduced))\n",
    "p3=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=4\")\n",
    "\n",
    "#k=5\n",
    "kmeans_model <- kmeans(velib_PCA_reduced, centers=5, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_PCA_reduced))\n",
    "p4=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=5\")\n",
    "\n",
    "grid.arrange(p1,p2,p3, p4,ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphe silouhette confirme les 3 clusters choisis à la méthode précédente: on a moins de valeurs négatives, les pics dépassent tous la moyenne (ligne rouge), qui est d'ailleurs la plus haute. On voit donc que 3 clusters est le meilleur choix pour Silhouette. \n",
    "\n",
    "\n",
    "Les méthodes Silouhette et inertie Intra ne donnent pas le même nombre de clusters. \n",
    "Nous choisissons arbitrairement 4 clusters pour la suite.\n",
    "\n",
    "## Projection des individus selon leur cluster faits sur les 4 composantes principales\n",
    "\n",
    "### Composantes 1 et 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On garde donc 4 clusters\n",
    "K = 4\n",
    "\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "#Sur le jeu de données réduit\n",
    "kmeans_pca <- kmeans(velib_PCA_reduced, centers = K, nstart = 10)\n",
    "\n",
    "#On obtient les clusters prédits\n",
    "clusters_pca <- kmeans_pca$cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot() + \n",
    "  geom_point(aes(x=velib_PCA_reduced[,1], y=velib_PCA_reduced[,2], col = as.factor(clusters_pca)))+\n",
    "  scale_color_manual(values = palette) +\n",
    "  labs(x = \"1ère composante principale\", y = \"2nde composante principale\", title = paste(\"Individuals factor map - Couleur selon les clusters k-means - Jeu réduit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Composantes 1 et 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot() + \n",
    "  geom_point(aes(x=velib_PCA_reduced[,1], y=velib_PCA_reduced[,3], col = as.factor(clusters_pca)))+\n",
    "  scale_color_manual(values = palette) + \n",
    "  labs(x = \"1ère composante principale\", y = \"3ème composante principale\", title = paste(\"Individuals factor map - Couleur selon les clusters k-means - Jeu réduit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection des individus selon leur cluster faits sur les données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_raw <- kmeans(loading, centers = K, nstart = 10)\n",
    "\n",
    "#On obtient les clusters prédits\n",
    "clusters_raw <- kmeans_raw$cluster\n",
    "\n",
    "ggplot() + \n",
    "  geom_point(aes(x=velib_PCA_reduced[,1], y=velib_PCA_reduced[,2], col = as.factor(clusters_raw)))+\n",
    "  scale_color_manual(values = palette) + \n",
    "  labs(x = \"1ère composante principale\", y = \"2nde composante principale\", title = paste(\"Individuals factor map - Couleur selon les clusters k-means - Jeu complet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que ces résultats entre les données brutes et les données réduites sont quasiment identiques.\n",
    "\n",
    "Ceci montre que les 4 premières composantes expliquent la majorité des données, on a donc très peu de perte d'information en réduisant la dimension.\n",
    "\n",
    "## Matrices de confusion pour comparer nos clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm <- table(clusters_pca, clusters_raw)\n",
    "clusters_kmean_raw_sorted <- clusters_raw[order(clusters_pca)]\n",
    "\n",
    "print(cm)\n",
    "image(cm, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo kmeans PCA\",\n",
    "      ylab = \"Avec l'algo kmeans sur les données complètes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve des grandes valeurs dans la diagonale, ce qui confirme les plots précédents : on a des résultats similaires sur le jeu de données complet et sur celui réduit (en gardant seulement les 4 composantes principales)\n",
    "\n",
    "\n",
    "## Visualiser par cartographie le Kmeans sur le jeu de données réduit et complet:\n",
    "\n",
    "### Jeu de données réduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_clusters <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_pca)\n",
    ")\n",
    "\n",
    "fig_cluster_pca <- plot_ly(data = df_clusters, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                           color = ~cluster, colors = palette[1:K],\n",
    "                           marker = list(size = 7), zoom = 10000, text = ~cluster,\n",
    "                           hoverinfo = \"text\") %>%\n",
    "  layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters kmeans on PCA data\"))\n",
    "\n",
    "fig_cluster_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeu de données complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_clusters <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_raw)\n",
    ")\n",
    "\n",
    "fig_cluster_raw <- plot_ly(data = df_clusters, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                           color = ~cluster, colors = palette[1:K],\n",
    "                           marker = list(size = 7), zoom = 10, text = ~cluster,\n",
    "                           hoverinfo = \"text\") %>%\n",
    "                   layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\"))\n",
    "\n",
    "fig_cluster_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il n'y a presque aucun changement entre les deux cartographies, que ce soit pour les clusters faits sur les données PCA, ou les clusters faits sur les données brutes. Ceci nous donne le même résultat qu'obtenu par la table de contingence. \n",
    "\n",
    "\n",
    "## Que représentent ces 4 clusters Kmeans sur les données réduites ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:K) {\n",
    "  indice <- which(clusters_pca == i)\n",
    "  data_subset <- loading[indice, ]\n",
    "  bp <- boxplot(data_subset, \n",
    "                col = (palette[1:K])[i], border = \"black\", median.col = \"red\",\n",
    "                staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "                names = rep(\"\", ncol(data_subset)))\n",
    "  \n",
    "  abline(v = seq(1, ncol(loading), length.out = 8), col = \"purple\", lty = \"dotted\")\n",
    "  \n",
    "  \n",
    "  title <- paste(\"Boxplot pour le cluster\", i)\n",
    "  ticks <- seq(0, 168, by = 5)\n",
    "  title(main = title, cex.main = 1.25)\n",
    "  axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "  labels <- seq(0, 168, by = 5)\n",
    "  mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "  mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "On obtient des différences significatives pour les 4 clusters : \n",
    "- Cluster n°1 : Vide le soir et le matin, plein dans l'après-midi.\n",
    "- Cluster n°2 : Inverse du n°1 : vide l'après-midi, plein le matin et le soir.\n",
    "- Cluster n°3 : Souvent vide en général, quasiment tout le temps vide de 8h à 18h.\n",
    "- Cluster n°4 : Souvent plein en général, quasiment tout le temps plein de 21h à 8h.\n",
    "\n",
    "Rq : La numérotation des clusters peut changer en fonction de la compilation.\n",
    "\n",
    "# Agglomerative Clustering\n",
    "\n",
    "## Choix optimal du nombre de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On choisit Ward pour la matrice de dissimilarités \n",
    "\n",
    "ac <- hclust(dist(velib_PCA_reduced), method = \"ward.D2\")\n",
    "\n",
    "#Nombre optimal de clusters avec WSS et Silhouette\n",
    "g1=fviz_nbclust(velib_PCA_reduced, FUN = hcut, method = \"wss\") + theme_minimal()\n",
    "g2=fviz_nbclust(velib_PCA_reduced, FUN = hcut, method = \"silhouette\") + theme_minimal()\n",
    "\n",
    "grid.arrange(g1,g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode du coude pour WSS nous suggere de prendre 4 clusters.\n",
    "Pour Silhouette on prendrait plutôt 3 clusters comme avec Kmeans.\n",
    "\n",
    "De même que pour Kmeans, on décide de garder arbitrairement 4 clusters.\n",
    "\n",
    "## Dendogramme coloré en fonction des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On prend 4 clusters\n",
    "K <- 4\n",
    "\n",
    "ac <- hclust(dist(velib_PCA_reduced), method = \"ward.D2\")\n",
    "\n",
    "#On trace un dendrogramme\n",
    "fviz_dend(ac,k=K)\n",
    "\n",
    "# title(\"Dendrogram with Ward linkage\") # ne marche pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit bien les 4 clusters, chaque couleur correspond à un cluster.\n",
    "\n",
    "## Projection des individus selon leur cluster faits sur les 4 composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "\n",
    "ac <- hclust(dist(velib_PCA_reduced), method = \"ward.D2\")\n",
    "#Découpage de l'arbre en K clusters\n",
    "clusters_ac <- cutree(ac, k = K)\n",
    "\n",
    "#Données PCA\n",
    "g2=ggplot(velib_PCA_reduced, aes(x = velib_PCA_reduced[,1], y = velib_PCA_reduced[,2], color = as.factor(clusters_ac))) +\n",
    "  geom_point(size = 1) +\n",
    "  scale_color_manual(values = palette) +\n",
    "  labs(title = \"Scatter plot with clusters : données PCA\") +\n",
    "  theme_minimal()\n",
    "g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Projection des individus selon leur cluster faits sur les données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On fait sur loading\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "# Clustering sur l'ensemble des données\n",
    "ac <- hclust(dist(loading), method = \"ward.D2\")\n",
    "clusters_ac_raw <- cutree(ac, k = K)\n",
    "\n",
    "#Données complètes\n",
    "g2=ggplot(velib_PCA_reduced, aes(x = velib_PCA_reduced[,1], y = velib_PCA_reduced[,2], color = as.factor(clusters_ac_raw))) +\n",
    "  geom_point(size = 1) +\n",
    "  scale_color_manual(values = palette) +\n",
    "  labs(title = \"Scatter plot with clusters : données complètes\") +\n",
    "  theme_minimal()\n",
    "g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "On voit encore une fois que les deux clustering sont similaires. On ne pert donc pas trop d'information en faisant une PCA.\n",
    "\n",
    "\n",
    "## Matrice de Confusion pour les clusters CAH sur le jeu de données réduit et brutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm <- table(clusters_ac, clusters_ac_raw)\n",
    "clusters_ac_raw_sorted <- clusters_ac_raw[order(clusters_ac)]\n",
    "\n",
    "print(cm)\n",
    "image(cm, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo CAH PCA\",\n",
    "      ylab = \"Avec l'algo CAH sur les données complètes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a des résultats similaires sur le jeu de données complet et sur celui réduit (en gardant seulement les 4 composantes principales), ce qui confirme les plots précédents.\n",
    "\n",
    "\n",
    "## Visualiser par cartographie le CAH sur le jeu de données réduit et complet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_clusters_pca <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_ac)\n",
    ")\n",
    "\n",
    "fig_cluster_pca2 <- plot_ly(data = df_clusters_pca, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~cluster, colors = palette[1:K],\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters CAH on PCA data\"))\n",
    "\n",
    "\n",
    "\n",
    "fig_cluster_pca2 <- fig_cluster_pca2 %>% layout(showlegend = TRUE)\n",
    "fig_cluster_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Fonction pour faire correspondre les classes\n",
    "matchClasses <- function(classif1, classif2) {\n",
    "  cm <- table(classif1, classif2)\n",
    "  K <- nrow(cm)\n",
    "  a <- numeric(K)\n",
    "  b <- numeric(K)\n",
    "  \n",
    "  for (j in 1:K) {\n",
    "    for (i in 1:K) {\n",
    "      if (a[j] < cm[i, j]) {\n",
    "        a[j] <- cm[i, j]\n",
    "        b[j] <- i\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  table <- cm\n",
    "  for (i in 1:K) {\n",
    "    table[, b[i]] <- cm[, i]\n",
    "  }\n",
    "  \n",
    "  clusters <- classif2\n",
    "  n <- length(classif2)\n",
    "  for (i in 1:n) {\n",
    "    for (j in 1:K) {\n",
    "      if (classif2[i] == j) {\n",
    "        clusters[i] <- b[j]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(list(table, clusters))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "result <- matchClasses(clusters_ac, clusters_ac_raw)\n",
    "clusters_ac_raw_sorted <- result[[2]]\n",
    "\n",
    "df_clusters_pca <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_ac_raw_sorted)\n",
    ")\n",
    "\n",
    "fig_cluster_ac_raw <- plot_ly(data = df_clusters_pca, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~cluster, colors = palette[1:K],\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters CAH on PCA data\"))\n",
    "\n",
    "\n",
    "\n",
    "fig_cluster_ac_raw <- fig_cluster_ac_raw %>% layout(showlegend = TRUE)\n",
    "fig_cluster_ac_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, on observe peu de différences dans l'ensemble, sauf en périphérie !\n",
    "\n",
    "## Comparaison clustering CAH et Kmeans sur données PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm <- table(clusters_ac, clusters_pca)\n",
    "print(cm)\n",
    "image(cm, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo CAH PCA\",\n",
    "      ylab = \"Avec l'algo Kmeans PCA\")\n",
    "\n",
    "adjustedRandIndex(clusters_ac, clusters_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque une forte correspondance entre les 2 méthodes de clustering. Kmeans et CAH mènent donc à des clusters similaires.\n",
    "Ceci est confimé par le ARI qui vaut 0.6 montrant une similarité entre ces deux clusterings.\n",
    "\n",
    "# Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gmm_model <- Mclust(velib_PCA_reduced, G = K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection du modèle et du nombre de clusters : Avec BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resBICall = mclustBIC(velib_PCA_reduced, G=2:12)\n",
    "summary(resBICall)\n",
    "\n",
    "resBICall\n",
    "\n",
    "resBICall = Mclust(velib_PCA_reduced, G=2:12)\n",
    "summary(resBICall)\n",
    "\n",
    "fviz_mclust(resBICall, what=\"BIC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le critère BIC sélectionne le modèle VVE (forme de la covariance : volumes différents, orientations égales et formes différentes)\n",
    "On garde aussi 12 classes (en regardant le max du BIC)\n",
    "\n",
    "\n",
    "# Projection des 12 clusters sur les 2 premières composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 13, repr.plot.height = 6)\n",
    "\n",
    "K = length(resBICall$parameters$mean[,][1,])\n",
    "model_name = resBICall$parameters$variance$modelName\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\", \"#589336\", \"#ae3f59\")\n",
    "\n",
    "resBIC = Mclust(velib_PCA_reduced, G=K, modelNames = model_name)\n",
    "fviz_cluster(resBIC, data=velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot des probabilités d'appartenance à une classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux = data.frame(\n",
    "    label = paste(\"Cluster\", resBIC$classification, sep=\"\"), \n",
    "    proba = apply(resBIC$z, 1, max))\n",
    "\n",
    "p1 = ggplot(aux, aes(x=label, y=proba)) + \n",
    "    geom_boxplot(colour=palette, fill=palette, alpha=.2)\n",
    "p2 = fviz_cluster(resBIC, data =velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\") +\n",
    "    ggtitle(\"\") + theme(legend.position = \"none\")\n",
    "\n",
    "grid.arrange(p1, p2, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe pour chaque cluster le boxplot des probas d'appartenance de chaque individu. Par exemple le cluster 5 est le mieux défini : la proba moyenne des individus est proche de 1 et la variance est faible, les individus sont donc tous quasiment certains d'appartenir à ce cluster, il y a peu de mal classés dans ce dernier.\n",
    "\n",
    "Au contraire, le cluster 9 a une grande variance est une moyenne de proba d'appartenance égale à 0.75, les individus sont donc moins certains d'appartenir à ce cluster.\n",
    "\n",
    "## Projection des clusters sur la carte de Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clusters_gmm <- resBIC$classification\n",
    "\n",
    "df_clusters_gmm <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_gmm)\n",
    ")\n",
    "\n",
    "fig_cluster_gmm <- plot_ly(data = df_clusters_gmm, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~cluster, colors = palette,\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters GMM on PCA data\"))\n",
    "\n",
    "\n",
    "\n",
    "fig_cluster_gmm <- fig_cluster_gmm %>% layout(showlegend = TRUE)\n",
    "fig_cluster_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Clusters semble bien trop. On a de nombreux clusters qui ont une variance énorme, et qui ne semblent rien expliquer. Tentons un autre critère de sélection.\n",
    "\n",
    "## Selection du modèle et du nombre de clusters : Avec ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resICLall_1 = mclustICL(velib_PCA_reduced, G=2:12, verbose = FALSE)\n",
    "summary(resICLall_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le critère ICL, on garde également le modèle VVE mais avec seulement 6 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(resICLall_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve bien le max d'ICL pour le modèle précédent.\n",
    "\n",
    "# Projection des 6 clusters sur les 2 premières composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 13, repr.plot.height = 6)\n",
    "\n",
    "K = 6\n",
    "model_name = \"VVE\"\n",
    "\n",
    "resICL = Mclust(velib_PCA_reduced, G=K, modelNames=model_name, verbose = FALSE)\n",
    "fviz_cluster(resICL, data=velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot des probabilités d'appartenance à une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "aux = data.frame(\n",
    "    label = paste(\"Cl\", resICL$classification, sep=\"\"), \n",
    "    proba = apply(resICL$z, 1, max))\n",
    "\n",
    "palette = palette[1:K]\n",
    "\n",
    "p1 = ggplot(aux, aes(x=label, y=proba)) + \n",
    "    geom_boxplot(colour=palette, fill=palette, alpha=.2)\n",
    "p2 = fviz_cluster(resBIC, data =velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\") +\n",
    "    ggtitle(\"\") + theme(legend.position = \"none\")\n",
    "\n",
    "grid.arrange(p1, p2, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on voit que les clusters 2,3 et 5 sont ceux où les individus ont une plus grande probabilité d'appartenance. On remarque en général que tous les clusters sont bien définis car les moyennes sont hautes.\n",
    "\n",
    "## Projection des 6 clusters sur la carte de Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clusters_gmm_icl <- resICL$classification\n",
    "\n",
    "df_clusters_gmm_icl <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_gmm_icl)\n",
    ")\n",
    "\n",
    "fig_cluster_gmm_icl <- plot_ly(data = df_clusters_gmm_icl, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~cluster, colors = palette,\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters GMM on PCA data\"))\n",
    "\n",
    "\n",
    "\n",
    "fig_cluster_gmm_icl <- fig_cluster_gmm_icl %>% layout(showlegend = TRUE)\n",
    "fig_cluster_gmm_icl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des 6 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:K) {\n",
    "  indice <- which(clusters_gmm_icl == i)\n",
    "  data_subset <- loading[indice, ]\n",
    "  bp <- boxplot(data_subset, \n",
    "                col = palette[i], border = \"black\", median.col = \"red\",\n",
    "                staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "                names = rep(\"\", ncol(data_subset)))\n",
    "  \n",
    "  abline(v = seq(1, ncol(loading), length.out = 8), col = \"purple\", lty = \"dotted\")\n",
    "  \n",
    "  \n",
    "  title <- paste(\"Boxplot pour le cluster\", i)\n",
    "  ticks <- seq(0, 168, by = 5)\n",
    "  labels <- seq(0, 168, by = 5)\n",
    "  title(main = title, cex.main = 1.25)\n",
    "  axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "  mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "  mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "} # faire en sorte que ordonnée fixe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1 : quartiers rédientiels (classe moyenne?) très déchargés de 8h à 18h(~0 de loading), un peu plus rechargés de 18h à 8h (~0.5 de loading) <br>\n",
    "Cluster 2 : le long de la seine, tourisme + études + gare : souvent chargés la journée (~0.9 de loading), plus déchargés en soirée et la nuit (~ 0.2 de loading)<br>\n",
    "Cluster 3 : bizarre, pas de tendance globale du tout. <br>\n",
    "Cluster 4 : on retrouve beaucoup de points d'intérêt, lieux de divertissements (tour eiffel, bercy, bastille) -> les gens s'y rendent plus qu'à d'autres endroits, ils y posent donc leur vélo en plus grand nombre : les stations plus souvent chargées. <br>\n",
    "Cluster 5 : Zones similaires au cluster 6, Stations délaissées : peu de variance, pas de chargement au dessus de 0.4. <br>\n",
    "Cluster 6 : champs élysées, opéra (zones d'intérêt, commerciales) : très chargé la journée, très déchargé le soir/nuit et le week-end -> surutilisé. <br>\n",
    "\n",
    "On peut trouver une bonne explication pour tous les clusters sauf le 3; beaucoup de variance, loading quasi tout le temps à 0.5... pas de comportement distinctif. On ne peut pas extraire d'information du cluster 3. De plus, les cluster 6 et 7 se ressemblent beaucoup. On va donc essayer de \"\"supprimer\"\" un cluster.\n",
    "\n",
    "## GMM avec 5 clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 13, repr.plot.height = 6)\n",
    "\n",
    "K = 5\n",
    "model_name = \"VVE\" # VVE semble être le meilleur paramètre selon BIC et ICL. \n",
    "\n",
    "resICL = Mclust(velib_PCA_reduced, G=K, modelNames=model_name, verbose = FALSE)\n",
    "fviz_cluster(resICL, data=velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\")\n",
    "\n",
    "# --- #\n",
    "\n",
    "aux = data.frame(\n",
    "    label = paste(\"Cl\", resICL$classification, sep=\"\"), \n",
    "    proba = apply(resICL$z, 1, max))\n",
    "\n",
    "palette = palette[1:K]\n",
    "\n",
    "p1 = ggplot(aux, aes(x=label, y=proba)) + \n",
    "    geom_boxplot(colour=palette, fill=palette, alpha=.4)\n",
    "p2 = fviz_cluster(resICL, data=velib_PCA_reduced, ellipse.type=\"norm\", geom=\"point\") +\n",
    "    ggtitle(\"\") + theme(legend.position = \"none\")\n",
    "\n",
    "grid.arrange(p1, p2, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on voit que le cluster n°3 est celui où les individus ont une plus grande probabilité d'appartenance. On remarque en général que tous les clusters sont bien définis car les moyennes sont hautes (on a par contre des variances plus grandes pour les autres clusters que le 3)\n",
    "\n",
    "## Projection des 5 clusters sur la carte de Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clusters_gmm_icl <- resICL$classification\n",
    "\n",
    "df_clusters_gmm_icl <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_gmm_icl)\n",
    ")\n",
    "\n",
    "fig_cluster_gmm_icl <- plot_ly(data = df_clusters_gmm_icl, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                    color = ~cluster, colors = palette,\n",
    "                    marker = list(size = 7), zoom = 10, text = paste(\"Loading:\", round(data24h, 2)),\n",
    "                    hoverinfo = \"text\") %>%\n",
    "            layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters GMM on PCA data\"))\n",
    "\n",
    "\n",
    "\n",
    "fig_cluster_gmm_icl <- fig_cluster_gmm_icl %>% layout(showlegend = TRUE)\n",
    "fig_cluster_gmm_icl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:K) {\n",
    "  indice <- which(clusters_gmm_icl == i)\n",
    "  data_subset <- loading[indice, ]\n",
    "  bp <- boxplot(data_subset, \n",
    "                col = palette[i], border = NULL, median.col = \"red\",\n",
    "                staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "                names = rep(\"\", ncol(data_subset)))\n",
    "  \n",
    "  abline(v = seq(1, ncol(loading), length.out = 8), col = \"purple\", lty = \"dotted\")\n",
    "  \n",
    "  \n",
    "  title <- paste(\"Boxplot pour le cluster\", i)\n",
    "  ticks <- seq(0, 168, by = 5)\n",
    "  labels <- seq(0, 168, by = 5)\n",
    "  title(main = title, cex.main = 1.25)\n",
    "  axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "  mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "  mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "} # faire en sorte que ordonnée fixe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1 : Vide en journée (8-18h, ~0 loading), plus rempli la nuit (~0.7 loading), et peu rempli le week-end\n",
    "Cluster 2 : Globalement plûtot rempli (~0.4/0.6), mais pas de comportement distinctif : trop de variance\n",
    "Cluster 3 : Plein en journée (8-18h, ~0.90 loading), plus vide la nuit (~0.1 loading). Tendance similaire le week-end.\n",
    "Cluster 4 : Plutôt rempli en journée (8-18h, ~0.90 loading), plus vide la nuit et le week-end (~0.1 loading).\n",
    "Cluster 5 : Globalement peu rempli. (~0.1 loading) Comportement \"chaotique\".\n",
    "\n",
    "Note : L'ordre des clusters est sujet à changer, mais l'interprétation de ces derniers reste la même. Ainsi, on obtient 4 clusters très cohérents, et remplis d'informations distinctives, tandis qu'un cluster reste moins intéressant.\n",
    "\n",
    "## Comparaison clustering GMM et Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm <- table(clusters_gmm_icl, clusters_pca)\n",
    "print(cm)\n",
    "image(cm, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo GMM sur PCA\",\n",
    "      ylab = \"Avec l'algo Kmeans PCA\")\n",
    "\n",
    "adjustedRandIndex(clusters_gmm_icl, clusters_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'index ajusté vaut 0.34 ce qui montre que les deux clusterings ne correspondent pas beaucoup.\n",
    "\n",
    "## Comparaison clustering GMM et CAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm <- table(clusters_gmm_icl, clusters_ac)\n",
    "print(cm)\n",
    "image(cm, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo GMM sur PCA\",\n",
    "      ylab = \"Avec l'algo CAH PCA\")\n",
    "adjustedRandIndex(clusters_gmm_icl, clusters_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'index ajusté vaut 0.32 ce qui montre que les deux clusterings correspondent encore moins que pour GMM et Kmeans\n",
    "\n",
    "## MCA\n",
    "\n",
    "Après avoir fait la PCA pour réduire les dimensions du jeu de données, on essyae de faire une MCA, c'est à dire une Analyse des Correspondances Multiples, sur le jeu de donnée entier.\n",
    "\n",
    "Comme pour la CA, la MCA fonctionne sur des variables qualitatives, donc on doit transformer les données en qualitatives avec des seuils ! Contrairement à la CA que l'on effectuait sur des matrices de confusions donc des données déjà qualitatives.\n",
    "\n",
    "## MCA sur toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seuils = list(\n",
    "    'Vide'= 0.2,\n",
    "    'Faible'= 0.4,\n",
    "    'Moyen'= 0.6,\n",
    "    'Fort'= 0.8,\n",
    "    'Pleine'= 1.0)\n",
    "\n",
    "seuilsV2 = list(\n",
    "    'Vide' = 0.33,\n",
    "    'Moyen' = 0.66,\n",
    "    'Pleine' = 1.0)\n",
    "\n",
    "seuilsV3 = list(\n",
    "    'Totalement Vide'= 0.1,\n",
    "    'Très Vide' = 0.2,\n",
    "    'Assez Faible' = 0.3,\n",
    "    'Faible' = 0.4,\n",
    "    'Moyen' = 0.5,\n",
    "    'Pas mal' = 0.6,\n",
    "    'Bien' = 0.7,\n",
    "    'Très Bien' = 0.8,\n",
    "    'Quasiment Pleine' = 0.9,\n",
    "    'Pleine' = 1.0\n",
    ")\n",
    "\n",
    "# Définis les seuils\n",
    "seuilsV4 = list(\n",
    "    'Vide'= 0.5,\n",
    "    'Plein'= 1\n",
    ")\n",
    "\n",
    "loading_quali <- data.frame(sapply(loading, function(col) cut(col, breaks = c(-Inf, unlist(seuils), Inf), labels = c(names(seuils), 'Pleine'))))\n",
    "loading_quali$hill <- data.frame(hill = Coord$bonus)\n",
    "loading_quali <- loading_quali %>% mutate(hill = case_when(loading_quali$hill==0 ~ \"Nohill\",\n",
    "                                         loading_quali$hill==1 ~ \"Hill\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide d'utiliser 5 seuils, on utilisera plus tard 3 seuils, car sur ce jeu de données on a beaucoup de variables qualitatives donc 3 modalités par variables pourrait être intéressant, mais nous voulions quand même essayer pour 5 seuils et voir à quel point la MCA est interprétable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res.mca <- MCA(loading_quali, graph = TRUE)\n",
    "\n",
    "head(res.mca$eig, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_var(res.mca, repel=TRUE)\n",
    "\n",
    "#On affiche les variables et leur modalités dans le plan des composantes 0 et 1 de la MCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphe ci-dessous est peu exploitable, car beaucoup trop encombré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "eig <- data.frame(res.mca$eig)\n",
    "\n",
    "tick = 1:length(eig$cumulative.percentage.of.variance)\n",
    "\n",
    "#Variance expliquée par composante principale\n",
    "barplot(height = eig$percentage.of.variance, names.arg = tick,\n",
    "        main = \"Variance expliquée par composante principale\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée\")\n",
    "\n",
    "barplot(height = eig$cumulative.percentage.of.variance, names.arg = tick,\n",
    "        main = \"Variance expliquée cumulée par composante principale de la MCA\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée cumulée\")\n",
    "abline(h = 70, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il nous faudrait garder à peu près 100 composantes pour expliquer 70% de la variance. Ainsi, on se rend compte que la MCA sur le jeu de données entier n'est pas du tout efficace en terme d'explication de variances, ce qui nous laisse penser que l'on devrait refaire une MCA sur un jeu de données légèrement modifié.\n",
    "\n",
    "On continue cependant légèrement l'analyse de cette MCA avant de modifier notre jeu de données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"hill\", # color by groups\n",
    "palette = c(\"blue\", \"#87e364\", \"#eb5656\", \"purple\", \"gold\"),\n",
    "axes = c(1,2)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"Lun.00\", # color by groups\n",
    "palette = c(\"blue\", \"#87e364\", \"#eb5656\", \"purple\", \"gold\"),\n",
    "axes = c(1,2)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"hill\", # color by groups\n",
    "palette = c(\"blue\", \"#87e364\", \"#eb5656\", \"purple\", \"gold\"),\n",
    "axes = c(2,3)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"Lun.00\", # color by groups\n",
    "palette = c(\"blue\", \"#87e364\", \"#eb5656\", \"purple\", \"gold\"),\n",
    "axes = c(2,3)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaye désormais de voir la contributions des colonnes, donc des variables qualitatives et de leur modalité, par les composantes de cette MCA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "contrib = res.mca$var$contrib\n",
    "head(contrib, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPLÉTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCA sur les données jours nuit\n",
    "\n",
    "Après avoir tester de faire une MCA sur le jeu de données dans son entierté nous décidons donc de regrouper les données. Comme nous remarquons depuis l'naalyse exploratoire que des séparations se faisaient au niveau du Jour/Nuit *(notamment via les corrplots)* et du Semaine/Week-end *(via le chargement moyen en fonction des jours et des heures notamment)* nous avons décider de séparer les données en journée et en nuit pour bien marquer cette différence tout en gardant les jours de la semaine et du week-end bien différentiable !\n",
    "\n",
    "Ainsi notre répartition est après analyse des corrplots de l'analyse descriptive : \n",
    "\n",
    "- **Jour : De 09h à 19h**\n",
    "\n",
    "- **Nuit : De 20h à 08h le lendemain** \n",
    "\n",
    "*(Exemple : Lundi nuit représente donc la période du Lundi 20h au Mardi 8h)*\n",
    "\n",
    "- **Et le week-end se tient donc de Vendredi nuit à Dimanche nuit compris !** Donc de Nuit 5 à Nuit 7 compris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X_quali <- data.frame(hill = Coord$bonus)\n",
    "X_quali <- X_quali %>% mutate(hill = case_when(X_quali$hill==0 ~ \"Nohill\",\n",
    "                                         X_quali$hill==1 ~ \"Hill\"))\n",
    "head(X_quali, n=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load = c('vide', 'moyen', 'chargé')\n",
    "for (i in 1:7){\n",
    "i_debut_jour = (i-1)*24 + 1 + 9\n",
    "i_fin_jour = i*24 - 4\n",
    "new_Col = rowMeans(loading[,i_debut_jour:i_fin_jour])\n",
    "print(loading[,i_debut_jour:i_fin_jour])\n",
    "breaks = c(-0.1,0.33, 0.66, 1.01)\n",
    "newCol = cut(new_Col, breaks = breaks, labels = load)\n",
    "colname = paste(\"Jour\", i, sep=\"\")\n",
    "X_quali[[colname]] = newCol\n",
    "}\n",
    "head(newCol)\n",
    "head(X_quali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "len_X = 24 * 7\n",
    "\n",
    "for (i in 1:7){\n",
    "  i_debut_nuit = i*24 - 3\n",
    "  if (i*24!=len_X){\n",
    "    i_fin_nuit = i*24 + 9\n",
    "    new_Col = rowMeans(loading[,i_debut_nuit:i_fin_nuit])\n",
    "  } else{\n",
    "    i_fin_nuit = (i*24 + 9) %% len_X\n",
    "    nuit_dimanche = group_by(loading[i_debut_nuit:len_X],loading[1:i_fin_nuit])\n",
    "    new_Col = rowMeans(nuit_dimanche)\n",
    "  }\n",
    "  breaks = c(-0.1,0.33, 0.66, 1.01)\n",
    "  newCol = cut(new_Col, breaks = breaks, labels = load)\n",
    "  colname = paste(\"Nuit\", i, sep=\"\")\n",
    "  X_quali[[colname]] = newCol\n",
    "  }\n",
    "\n",
    "head(newCol)\n",
    "head(X_quali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res.mca <- MCA(X_quali, graph = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "eig <- data.frame(res.mca$eig)\n",
    "\n",
    "tick = 1:length(eig$cumulative.percentage.of.variance)\n",
    "\n",
    "#Variance expliquée par composante principale\n",
    "barplot(height = eig$percentage.of.variance, names.arg = tick,\n",
    "        main = \"Variance expliquée par composante principale\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée\")\n",
    "\n",
    "barplot(height = eig$cumulative.percentage.of.variance, names.arg = tick,\n",
    "        main = \"Variance expliquée cumulée par composante principale de la MCA\",\n",
    "        xlab = \"Composante principale\",\n",
    "        ylab = \"Variance expliquée cumulée\")\n",
    "abline(h = 70, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour 3 seuils à \"0.33\", \"0.66\" et \"1\" on a besoin de 10 composantes pour expliquer 70% de la variance ainsi on a beaucoup plus de composantes qu'en PCA, ce qui rend le jeu de données MCA plus complexe à manipuler si l'on veut conserver une bonne explication de la variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"Jour2\", # color by groups\n",
    "palette = c(\"#87e364\", \"#ffd338\", \"#eb5656\"),\n",
    "axes = c(1,2)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"Jour2\", # color by groups\n",
    "palette = c(\"#87e364\", \"#ffd338\", \"#eb5656\"),\n",
    "axes = c(1, 3)\n",
    "#addEllipses = TRUE, ellipse.type = \"confidence\",\n",
    ")\n",
    "\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"hill\", # color by groups\n",
    "palette = c(\"steelblue\", \"orange\"),\n",
    "axes = c(1,2)\n",
    ")\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\", # hide individual labels\n",
    "habillage = \"hill\", # color by groups\n",
    "palette = c(\"steelblue\", \"orange\"),\n",
    "axes = c(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les stations Hill ont l'air d'être assez regroupées sur les dimensions ci-dessus, de mêmes que pour les modalités faible et forte de la journée du Mardi, ce qui est assez intéressant quand on compare cela à la MCA sur le jeu de données pas transformés !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "C <- as.data.frame(res.mca$ind$coord)\n",
    "velib_MCA_reduced <- C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "contrib = res.mca$var$contrib\n",
    "head(contrib, 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des contributions, ainsi que de la qualité de représentation dans le plan MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_var(res.mca, col.var = \"contrib\", repel = TRUE, gradient.cols = c(\"#00afbb\",\"red\",\"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_var(res.mca, col.var = \"cos2\", repel = TRUE, gradient.cols = c(\"#00afbb\",\"red\",\"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\",\n",
    "col.ind = \"contrib\",\n",
    "axes = c(1,2))\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\",\n",
    "col.ind = \"cos2\",\n",
    "axes = c(1,2))\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\",\n",
    "col.ind = \"contrib\",\n",
    "axes = c(1,3))\n",
    "\n",
    "fviz_mca_ind(res.mca,\n",
    "label = \"none\",\n",
    "col.ind = \"cos2\",\n",
    "axes = c(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après analyse de la MCA, on remarque donc qu'elle peut être assez pertinente pour réduire les dimensions de notre jeu de données Vélib, mais on préfèrerait quand même garder la PCA car on n'y utilise que 4 dimensions, la ou la MCA nous en fait utiliser 10.\n",
    "\n",
    "### Clustering Kmeans sur les données MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "K=10\n",
    "Iintra=NULL\n",
    "for (k in 2:K)\n",
    "{\n",
    "  #On calcule l'inertie pour différentes valeurs de k\n",
    "  kmeans_model <- kmeans(velib_MCA_reduced, centers = k)\n",
    "  Iintra=c(Iintra,kmeans_model$tot.withinss)\n",
    "  \n",
    "}\n",
    "inertie_df=data.frame(K=2:10,Iintra=Iintra)\n",
    "ggplot(inertie_df,aes(x=K,y=Iintra))+geom_line()+geom_point()+ \n",
    "  labs(x = \"Nombre de clusters (k)\", y = \"Inertie\") +\n",
    "  ggtitle(\"Dispersion de l'inertie en fonction de k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On garderait 3 clusters d'après la méthode du coude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "g1=fviz_nbclust(velib_MCA_reduced, stats::kmeans, method = \"silhouette\")\n",
    "g2=fviz_nbclust(velib_MCA_reduced, stats::kmeans, method = \"wss\")\n",
    "grid.arrange(g1,g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La méthode silhouette propose 9 clusters mais cela paraît trop, et à partir de 2 clusters le score silhouette est quasi constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 6)\n",
    "\n",
    "#On teste pour plusieurs k différents\n",
    "\n",
    "#k=2\n",
    "kmeans_model <- kmeans(velib_MCA_reduced, centers=2, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_MCA_reduced))\n",
    "p1=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=2\")\n",
    "\n",
    "#k=3\n",
    "kmeans_model <- kmeans(velib_MCA_reduced, centers=3, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_MCA_reduced))\n",
    "p2=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=3\")\n",
    "\n",
    "#k=4\n",
    "kmeans_model <- kmeans(velib_MCA_reduced, centers=4, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_MCA_reduced))\n",
    "p3=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=4\")\n",
    "\n",
    "#k=5\n",
    "kmeans_model <- kmeans(velib_MCA_reduced, centers=5, nstart=10)\n",
    "silhouette_vals <- silhouette(kmeans_model$cluster, dist(velib_MCA_reduced))\n",
    "p4=fviz_silhouette(silhouette_vals, main=\"Silhouette for k=5\")\n",
    "\n",
    "grid.arrange(p1,p2,p3, p4,ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comme vu précédemment, le score silhouette n'invalide pas de clusters en dessous de 5. Prenons arbitrairement K = 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#On garde donc 4 clusters\n",
    "K = 5\n",
    "\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "#Sur le jeu de données réduit\n",
    "kmeans_mca <- kmeans(velib_MCA_reduced, centers = K, nstart = 10)\n",
    "\n",
    "#On obtient les clusters prédits\n",
    "clusters_mca <- kmeans_mca$cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(velib_MCA_reduced)\n",
    "\n",
    "ggplot() + \n",
    "  geom_point(aes(x=velib_MCA_reduced[,1], y=velib_MCA_reduced[,2], col = as.factor(clusters_mca)))+\n",
    "  scale_color_manual(values = palette) +\n",
    "  labs(x = \"1ère composante principale\", y = \"2nde composante principale\", title = paste(\"Individuals factor map - Couleur selon les clusters k-means - Jeu réduit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_clusters <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_mca)\n",
    ")\n",
    "\n",
    "fig_cluster_mca <- plot_ly(data = df_clusters, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                           color = ~cluster, colors = palette[1:K],\n",
    "                           marker = list(size = 7), zoom = 10000, text = ~cluster,\n",
    "                           hoverinfo = \"text\") %>%\n",
    "  layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters kmeans on MCA data\"))\n",
    "\n",
    "fig_cluster_mca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "#Sur le jeu de données réduit\n",
    "kmeans_raw <- kmeans(loading, centers = K, nstart = 10)\n",
    "\n",
    "#On obtient les clusters prédits\n",
    "clusters_raw <- kmeans_raw$cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_clusters <- data.frame(\n",
    "  latitude = Position[,2],\n",
    "  longitude = Position[,1],\n",
    "  cluster = as.factor(clusters_raw)\n",
    ")\n",
    "\n",
    "fig_cluster_raw <- plot_ly(data = df_clusters, x = ~longitude, y = ~latitude, type = \"scattermapbox\",\n",
    "                           color = ~cluster, colors = palette[1:K],\n",
    "                           marker = list(size = 7), zoom = 10000, text = ~cluster,\n",
    "                           hoverinfo = \"text\") %>%\n",
    "  layout(mapbox = list(center = list(lon = paris_lon, lat = paris_lat),\n",
    "                                 zoom = 10, style = \"carto-positron\",title = \"Individual factor map with clusters kmeans on raw data\"))\n",
    "\n",
    "fig_cluster_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##Interprétation des 5 clusters\n",
    "\n",
    "for (i in 1:K){\n",
    "  indice <- which(clusters_mca == i)\n",
    "  data_subset <- loading[indice, ]\n",
    "  bp <- boxplot(data_subset, \n",
    "                col = palette[i], border = NULL, median.col = \"red\",\n",
    "                staplewex = 0, notch = FALSE, outline = FALSE,\n",
    "                names = rep(\"\", ncol(data_subset)))\n",
    "  \n",
    "  abline(v = seq(1, ncol(loading), length.out = 8), col = \"purple\", lty = \"dotted\")\n",
    "  \n",
    "  \n",
    "  title <- paste(\"Boxplot pour le cluster\", i)\n",
    "  ticks <- seq(0, 168, by = 5)\n",
    "  labels <- seq(0, 168, by = 5)\n",
    "  title(main = title, cex.main = 1.25)\n",
    "  axis(1, at = ticks, labels = labels, cex.axis = 1.25)\n",
    "  mtext(\"Time\", side = 1, line = 2, cex = 1.5)\n",
    "  mtext(\"Loading\", side = 2, line = 2, cex = 1.5)\n",
    "} # faire en sorte que ordonnée fixe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve la même chose que précédemment pour le modèle GMM : On a 4 clusters bien ajustés, mais un cluster possède trop de variance, et n'est pas analysable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des clusters sur le jeu de données MCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec le jeu de données complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#on calcule la matrice de confusion\n",
    "cm_mca <- table(clusters_mca, clusters_raw)\n",
    "clusters_kmean_raw_sorted <- clusters_raw[order(clusters_mca)]\n",
    "\n",
    "print(cm_mca)\n",
    "image(cm_mca, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo kmeans MCA\",\n",
    "      ylab = \"Avec l'algo kmeans sur les données complètes\")\n",
    "adjustedRandIndex(clusters_mca, clusters_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque une bonne similarité car la matrice est quasiment diagonale, donc on pourrait dire que la MCA conserve bien les particularités jeu de données tout en réduisant les dimensions.\n",
    "Ensuite on peut comparer le clustering MCA avec le clustering PCA voir s'ils sont similaire, si oui, on pourrait en déduire que le PCA est définitivement mieux a uvu de son nombre de dimensions inférieurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec le jeu de données PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "\n",
    "palette = c(\"#8dd3c7\", \"#ffffb3\", \"#db564d\", \"#64ade8\", \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\")\n",
    "\n",
    "#Sur le jeu de données réduit\n",
    "kmeans_pca <- kmeans(velib_PCA_reduced, centers = K, nstart = 10)\n",
    "\n",
    "#On obtient les clusters prédits\n",
    "clusters_pca <- kmeans_pca$cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cm_mca_pca <- table(clusters_mca, clusters_pca)\n",
    "clusters_kmean_pca_sorted <- clusters_pca[order(clusters_mca)]\n",
    "\n",
    "print(cm_mca_pca)\n",
    "image(cm_mca_pca, main = \"Matrice de confusion\",\n",
    "      xlab = \"Avec l'algo kmeans MCA\",     \n",
    "      ylab = \"Avec l'algo kmeans sur les données complètes\")\n",
    "adjustedRandIndex(clusters_mca, clusters_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque également une bonne similarité car la matrice est quasiment diagonale et à un ARI de presque 70%, donc on pourrait dire que la MCA et la PCA ont des clsuterings similaires avec kmeans, mais que la PCA réduit mieux les dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
